{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5Y8OQwrpFMc"
      },
      "source": [
        "### **Dataset: GoEmotions**\n",
        "\n",
        "*GoEmotions* is a corpus of 58k carefully curated comments extracted from Reddit, with human annotations to 27 emotion categories or Neutral.\n",
        "\n",
        "Number of examples: 58,009.\n",
        "Number of labels: 27 + Neutral.\n",
        "\n",
        "The data has already been separated in train, test and validation sets\n",
        "\n",
        "Size of training dataset: 43,410.\n",
        "\n",
        "Size of test dataset: 5,427.\n",
        "\n",
        "Size of validation dataset: 5,426.\n",
        "\n",
        "The emotion categories are: admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTi5KyigsIHP"
      },
      "source": [
        "Importing libraries and importing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in c:\\users\\nishi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (23.2.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.13.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOVsDihbriSd",
        "outputId": "93249a17-e840-42e5-b594-ae42929c0585"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.13.0\n"
          ]
        }
      ],
      "source": [
        "# Here we import everything we need for the project\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#import cv2\n",
        "import pandas as pd\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.model_selection import train_test_split # Helps with organizing data for training\n",
        "from sklearn.metrics import confusion_matrix # Helps present results as a confusion-matrix\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7S44BBOwrWAA"
      },
      "outputs": [],
      "source": [
        "# Importing raw comments and labels\n",
        "df_train = pd.read_csv('train.tsv', sep='\\t', header=None, names=['Text', 'GE_indices', 'Id']).drop('Id', axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(43410, 2)\n"
          ]
        }
      ],
      "source": [
        "print(df_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_val = pd.read_csv('dev.tsv', sep='\\t', header=None, names=['Text', 'GE_indices', 'Id']).drop('Id', axis=1)\n",
        "df_test = pd.read_csv('test.tsv', sep='\\t', header=None, names=['Text', 'GE_indices', 'Id']).drop('Id', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "eZvcKUaHrr72",
        "outputId": "c62cb12b-ec95-499f-e44f-f2790c6f7fc9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>GE_indices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My favourite food is anything I didn't have to...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now if he does off himself, everyone will thin...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To make her feel threatened</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dirty Southern Wankers</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43405</th>\n",
              "      <td>Added you mate well I’ve just got the bow and ...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43406</th>\n",
              "      <td>Always thought that was funny but is it a refe...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43407</th>\n",
              "      <td>What are you talking about? Anything bad that ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43408</th>\n",
              "      <td>More like a baptism, with sexy results!</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43409</th>\n",
              "      <td>Enjoy the ride!</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43410 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    Text GE_indices\n",
              "0      My favourite food is anything I didn't have to...         27\n",
              "1      Now if he does off himself, everyone will thin...         27\n",
              "2                         WHY THE FUCK IS BAYLESS ISOING          2\n",
              "3                            To make her feel threatened         14\n",
              "4                                 Dirty Southern Wankers          3\n",
              "...                                                  ...        ...\n",
              "43405  Added you mate well I’ve just got the bow and ...         18\n",
              "43406  Always thought that was funny but is it a refe...          6\n",
              "43407  What are you talking about? Anything bad that ...          3\n",
              "43408            More like a baptism, with sexy results!         13\n",
              "43409                                    Enjoy the ride!         17\n",
              "\n",
              "[43410 rows x 2 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preview of what data has been saved in the above variables\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "CnSH_ssPr0_G",
        "outputId": "812e3fa0-bb69-4543-e622-2128040e67cc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>GE_indices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I’m really sorry about your situation :( Altho...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It's wonderful because it's awful. At not with.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kings fan here, good luck to you guys! Will be...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I didn't know that, thank you for teaching me ...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>They got bored from haunting earth for thousan...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5422</th>\n",
              "      <td>Thanks. I was diagnosed with BP 1 after the ho...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5423</th>\n",
              "      <td>Well that makes sense.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5424</th>\n",
              "      <td>Daddy issues [NAME]</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5425</th>\n",
              "      <td>So glad I discovered that subreddit a couple m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5426</th>\n",
              "      <td>Had to watch \"Elmo in Grouchland\" one time too...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5427 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text GE_indices\n",
              "0     I’m really sorry about your situation :( Altho...         25\n",
              "1       It's wonderful because it's awful. At not with.          0\n",
              "2     Kings fan here, good luck to you guys! Will be...         13\n",
              "3     I didn't know that, thank you for teaching me ...         15\n",
              "4     They got bored from haunting earth for thousan...         27\n",
              "...                                                 ...        ...\n",
              "5422  Thanks. I was diagnosed with BP 1 after the ho...         15\n",
              "5423                             Well that makes sense.          4\n",
              "5424                                Daddy issues [NAME]         27\n",
              "5425  So glad I discovered that subreddit a couple m...          0\n",
              "5426  Had to watch \"Elmo in Grouchland\" one time too...         27\n",
              "\n",
              "[5427 rows x 2 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "HJiaYsiWr59V",
        "outputId": "44166cfe-ae10-4459-d377-05b531c0007b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>GE_indices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Is this in New Orleans?? I really feel like th...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>You know the answer man, you are programmed to...</td>\n",
              "      <td>4,27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I've never been this sad in my life!</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The economy is heavily controlled and subsidiz...</td>\n",
              "      <td>4,27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>He could have easily taken a real camera from ...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5421</th>\n",
              "      <td>It's pretty dangerous when the state decides w...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5422</th>\n",
              "      <td>I filed for divorce this morning. Hoping he mo...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5423</th>\n",
              "      <td>The last time it happened I just said, \"No\" an...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5424</th>\n",
              "      <td>I can’t stand this arrogant prick he’s no bett...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5425</th>\n",
              "      <td>::but I like baby bangs:: /tiny voice</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5426 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text GE_indices\n",
              "0     Is this in New Orleans?? I really feel like th...         27\n",
              "1     You know the answer man, you are programmed to...       4,27\n",
              "2                  I've never been this sad in my life!         25\n",
              "3     The economy is heavily controlled and subsidiz...       4,27\n",
              "4     He could have easily taken a real camera from ...         20\n",
              "...                                                 ...        ...\n",
              "5421  It's pretty dangerous when the state decides w...         14\n",
              "5422  I filed for divorce this morning. Hoping he mo...         20\n",
              "5423  The last time it happened I just said, \"No\" an...         10\n",
              "5424  I can’t stand this arrogant prick he’s no bett...          3\n",
              "5425              ::but I like baby bangs:: /tiny voice         18\n",
              "\n",
              "[5426 rows x 2 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3QliWrFshzH"
      },
      "source": [
        "Finding out how much percentage of data is represented by each"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "e_ovGp7BsXhz"
      },
      "outputs": [],
      "source": [
        "# Defining the number of samples in train, validation and test dataset\n",
        "size_train = df_train.shape[0]\n",
        "size_val = df_val.shape[0]\n",
        "size_test = df_test.shape[0]\n",
        "\n",
        "# Defining the total number of samples\n",
        "size_all = size_train + size_val + size_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uUlMrKPssJt",
        "outputId": "92a60e38-28a4-411c-dd1b-98cdb502aa46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset has 43410 samples and represents 80.00% of overall data\n",
            "Validation dataset has 5426 samples and represents 10.00% of overall data\n",
            "Test dataset has 5427 samples and represents 10.00% of overall data\n",
            "\n",
            "The total number of samples is : 54263\n"
          ]
        }
      ],
      "source": [
        "# Shape of train, validation and test datasets\n",
        "print(\"Train dataset has {} samples and represents {:.2f}% of overall data\".format(size_train, size_train/size_all*100))\n",
        "print(\"Validation dataset has {} samples and represents {:.2f}% of overall data\".format(size_val, size_val/size_all*100))\n",
        "print(\"Test dataset has {} samples and represents {:.2f}% of overall data\".format(size_test, size_test/size_all*100))\n",
        "print()\n",
        "print(\"The total number of samples is : {}\".format(size_all))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZb5dVCDuHsc"
      },
      "source": [
        "Finding out number of emotions in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEAVtLzFuMJW",
        "outputId": "f2be1318-47b1-4d15-fe4d-3ced26a50733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 43410 entries, 0 to 43409\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Text        43410 non-null  object\n",
            " 1   GE_indices  43410 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 678.4+ KB\n"
          ]
        }
      ],
      "source": [
        "#For datatype\n",
        "df_train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q6pRoEfus82"
      },
      "source": [
        "Now, emotions.txt has all the set of emotions that this dataset contains.\n",
        "\n",
        "Each emotion is mapped to a number as well, according to the sequence it is in, in the emotions.txt text file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MspR94jFur1i",
        "outputId": "cd52481a-6297-4311-8d5d-1925f26ed789"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n"
          ]
        }
      ],
      "source": [
        "# Loading emotion labels for classification of emotions in GoEmotions dataset\n",
        "with open(\"emotions.txt\", \"r\") as file:\n",
        "    GE_class = file.read().split(\"\\n\")\n",
        "\n",
        "print(GE_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "S05jRnQo-ckg",
        "outputId": "d1cc4954-3f5f-48ca-8f36-cfc6f4d9b639"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'sadness'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "GE_class[25]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwnrzOkVxlPv",
        "outputId": "1d48cfe0-2977-4f11-cf77-c363cb451ffa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28\n"
          ]
        }
      ],
      "source": [
        "print(len(GE_class))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO57v_WtzGFC"
      },
      "source": [
        "Hence, there are 28 emotions, including 'neutral'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7smi9we0e99",
        "outputId": "fb259a03-a638-4e78-ec0b-2236be35de17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GE_indices\n",
              "27           12823\n",
              "0             2710\n",
              "4             1873\n",
              "15            1857\n",
              "1             1652\n",
              "             ...  \n",
              "6,15,22          1\n",
              "9,10,19          1\n",
              "7,10,25          1\n",
              "7,9,24,25        1\n",
              "0,1,18           1\n",
              "Name: count, Length: 711, dtype: int64"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Counting the number of values under each emotion category\n",
        "df_train.GE_indices.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tWxlFaT1Imr"
      },
      "source": [
        "###Lambda Functions\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "They can have any number of arguments but only one expression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiHIQbvY1a-R"
      },
      "source": [
        "Before we start to further process the data, we will first have to combine all the three datasets into one and then proceed further"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "vRiCC_Zp1l0g",
        "outputId": "8c45a685-6af5-4855-9be6-11492e9ce819"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>GE_indices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My favourite food is anything I didn't have to...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now if he does off himself, everyone will thin...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text GE_indices\n",
              "0  My favourite food is anything I didn't have to...         27\n",
              "1  Now if he does off himself, everyone will thin...         27\n",
              "2                     WHY THE FUCK IS BAYLESS ISOING          2"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(54263, 2)\n"
          ]
        }
      ],
      "source": [
        "# Combining all the 3 datasets into 1 dataset\n",
        "df_all = pd.concat([df_train, df_val, df_test], axis=0).reset_index(drop=True)\n",
        "\n",
        "# Preview of data\n",
        "display(df_all.head(3))\n",
        "\n",
        "print(df_all.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQN_kry62DyE"
      },
      "source": [
        "Next, we will have to map each GE_indices to it's corresponding emotion in the emotions.txt file\n",
        "\n",
        "For that, let's first convert these GE_indices into a list of indices which we will then map to the emotions.txt file and extract the emotion labels from the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "Oeod5_DR2bVi"
      },
      "outputs": [],
      "source": [
        "# We will use a lambda function here to make things easier\n",
        "#df_all['GE_indices'] = df_all['GE_indices'].apply(lambda x: x.split(','))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp6oC2u92nN4",
        "outputId": "edfecb14-7d02-4e0e-f513-77395b03e5e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of                                                     Text GE_indices\n",
            "0      My favourite food is anything I didn't have to...         27\n",
            "1      Now if he does off himself, everyone will thin...         27\n",
            "2                         WHY THE FUCK IS BAYLESS ISOING          2\n",
            "3                            To make her feel threatened         14\n",
            "4                                 Dirty Southern Wankers          3\n",
            "...                                                  ...        ...\n",
            "54258  Thanks. I was diagnosed with BP 1 after the ho...         15\n",
            "54259                             Well that makes sense.          4\n",
            "54260                                Daddy issues [NAME]         27\n",
            "54261  So glad I discovered that subreddit a couple m...          0\n",
            "54262  Had to watch \"Elmo in Grouchland\" one time too...         27\n",
            "\n",
            "[54263 rows x 2 columns]>\n"
          ]
        }
      ],
      "source": [
        "# Viewing the data for results\n",
        "print(df_all.head)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svvIA4jx1msX"
      },
      "source": [
        "Next steps:\n",
        "1. Determine which emotions we want\n",
        "2. Drop accordingly\n",
        "3. Tokenization\n",
        "4. Embedding\n",
        "5. Vectorization\n",
        "6. Models building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgA59yV2qP2o",
        "outputId": "d15493aa-4846-4646-ac94-407e191ec148"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text          0\n",
              "GE_indices    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "8x04O6GyqwkT",
        "outputId": "326a2063-012a-476a-a351-ff3594e8abb4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>GE_indices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My favourite food is anything I didn't have to...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now if he does off himself, everyone will thin...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To make her feel threatened</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dirty Southern Wankers</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54258</th>\n",
              "      <td>Thanks. I was diagnosed with BP 1 after the ho...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54259</th>\n",
              "      <td>Well that makes sense.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54260</th>\n",
              "      <td>Daddy issues [NAME]</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54261</th>\n",
              "      <td>So glad I discovered that subreddit a couple m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54262</th>\n",
              "      <td>Had to watch \"Elmo in Grouchland\" one time too...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54263 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    Text GE_indices\n",
              "0      My favourite food is anything I didn't have to...         27\n",
              "1      Now if he does off himself, everyone will thin...         27\n",
              "2                         WHY THE FUCK IS BAYLESS ISOING          2\n",
              "3                            To make her feel threatened         14\n",
              "4                                 Dirty Southern Wankers          3\n",
              "...                                                  ...        ...\n",
              "54258  Thanks. I was diagnosed with BP 1 after the ho...         15\n",
              "54259                             Well that makes sense.          4\n",
              "54260                                Daddy issues [NAME]         27\n",
              "54261  So glad I discovered that subreddit a couple m...          0\n",
              "54262  Had to watch \"Elmo in Grouchland\" one time too...         27\n",
              "\n",
              "[54263 rows x 2 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYUpoqk8sFO6"
      },
      "source": [
        "Dropping the un required emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "9XCVR6z-FLsx"
      },
      "outputs": [],
      "source": [
        "j=['0','1','3','4','5','6','7','8','9','10','11','12','13','15','16','18','19','20','21','22','23','24','26','27']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9LwbFy2CfB2",
        "outputId": "1402dc6a-cc15-41ec-bd9e-2ea29fe5dfa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "9\n",
            "14\n",
            "17\n",
            "26\n",
            "27\n",
            "                                                    Text GE_indices\n",
            "2                         WHY THE FUCK IS BAYLESS ISOING          2\n",
            "17                                       Fucking coward.          2\n",
            "25                 Stupidly stubborn / stubbornly stupid          2\n",
            "30     Troll, bro. They know they're saying stupid sh...          2\n",
            "116                                  The fuck is “mog?!”          2\n",
            "...                                                  ...        ...\n",
            "54254                             The essay is optional.         27\n",
            "54256        Waiting for both of these things is torture         27\n",
            "54257  Easy just include [NAME] to continue to tormen...         27\n",
            "54260                                Daddy issues [NAME]         27\n",
            "54262  Had to watch \"Elmo in Grouchland\" one time too...         27\n",
            "\n",
            "[20681 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# 2:anger, 9:disappointment, 14:fear, 17:joy, 26:surprise, 27:neutral\n",
        "df_final2 = pd.DataFrame()\n",
        "emotions_selected=['2','9','14','17','26','27']#\n",
        "\n",
        "for i in range(6):\n",
        "   df_final2=df_final2._append(df_all.loc[df_all['GE_indices'] == emotions_selected[i]])\n",
        "   print(emotions_selected[i])\n",
        "\n",
        "print (df_final2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "13-bcb4hFvfz",
        "outputId": "19a10ed1-96c0-4278-e7fb-297c601f94ec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>GE_indices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Fucking coward.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Stupidly stubborn / stubbornly stupid</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Troll, bro. They know they're saying stupid sh...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>The fuck is “mog?!”</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Text GE_indices\n",
              "2                       WHY THE FUCK IS BAYLESS ISOING          2\n",
              "17                                     Fucking coward.          2\n",
              "25               Stupidly stubborn / stubbornly stupid          2\n",
              "30   Troll, bro. They know they're saying stupid sh...          2\n",
              "116                                The fuck is “mog?!”          2"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "x1P5nff4KYMy"
      },
      "outputs": [],
      "source": [
        "one_hot_encoded_data = pd.get_dummies(df_final2, columns = ['GE_indices'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "I8pZhZBfKjZD",
        "outputId": "506443fd-0f35-4f9d-b418-e3a2fae63345"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>GE_indices_14</th>\n",
              "      <th>GE_indices_17</th>\n",
              "      <th>GE_indices_2</th>\n",
              "      <th>GE_indices_26</th>\n",
              "      <th>GE_indices_27</th>\n",
              "      <th>GE_indices_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Fucking coward.</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Stupidly stubborn / stubbornly stupid</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Troll, bro. They know they're saying stupid sh...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>The fuck is “mog?!”</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Text  GE_indices_14  \\\n",
              "2                       WHY THE FUCK IS BAYLESS ISOING          False   \n",
              "17                                     Fucking coward.          False   \n",
              "25               Stupidly stubborn / stubbornly stupid          False   \n",
              "30   Troll, bro. They know they're saying stupid sh...          False   \n",
              "116                                The fuck is “mog?!”          False   \n",
              "\n",
              "     GE_indices_17  GE_indices_2  GE_indices_26  GE_indices_27  GE_indices_9  \n",
              "2            False          True          False          False         False  \n",
              "17           False          True          False          False         False  \n",
              "25           False          True          False          False         False  \n",
              "30           False          True          False          False         False  \n",
              "116          False          True          False          False         False  "
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "one_hot_encoded_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text             object\n",
              "GE_indices_14      bool\n",
              "GE_indices_17      bool\n",
              "GE_indices_2       bool\n",
              "GE_indices_26      bool\n",
              "GE_indices_27      bool\n",
              "GE_indices_9       bool\n",
              "dtype: object"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "one_hot_encoded_data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVHBtj5hEUKq",
        "outputId": "1f1abf8e-bc4d-470e-c9dd-e991e89209d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GE_indices\n",
              "27    16021\n",
              "2      1265\n",
              "17     1052\n",
              "26      902\n",
              "9       888\n",
              "14      553\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final2.GE_indices.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "xrAf6vrBqzYa"
      },
      "outputs": [],
      "source": [
        "X = df_final2.iloc[:, 0].values\n",
        "Y = one_hot_encoded_data.iloc[:, 1:7].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQWR8N_IrsNZ",
        "outputId": "92bc5ca6-5f47-45a0-df61-23b934d71059"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['WHY THE FUCK IS BAYLESS ISOING', 'Fucking coward.',\n",
              "       'Stupidly stubborn / stubbornly stupid', ...,\n",
              "       'Easy just include [NAME] to continue to torment [NAME]',\n",
              "       'Daddy issues [NAME]',\n",
              "       'Had to watch \"Elmo in Grouchland\" one time too many when my kids were little...musical Elmo / Oscar overdose...'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPyhSpk-rssY",
        "outputId": "ad76415f-81c3-4c11-add4-0d8d89e04515"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[False, False,  True, False, False, False],\n",
              "       [False, False,  True, False, False, False],\n",
              "       [False, False,  True, False, False, False],\n",
              "       ...,\n",
              "       [False, False, False, False,  True, False],\n",
              "       [False, False, False, False,  True, False],\n",
              "       [False, False, False, False,  True, False]])"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6wTKkV_ruIQ",
        "outputId": "909eb2d3-3e0c-4fa2-8429-aa89c126570d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20681,)\n",
            "(20681, 6)\n"
          ]
        }
      ],
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgZZYenaIhId"
      },
      "source": [
        "###Split data  into training and validation sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "ZaCoR_aZIf34"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "QQOCuyf4Io9R"
      },
      "outputs": [],
      "source": [
        "train_sentences, val_sentences, train_labels, val_labels= train_test_split(X,\n",
        "                                                                           Y,\n",
        "                                                                           test_size=0.1,#use 20%of training data for validation\n",
        "                                                                           random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoIcyuqPI_5h",
        "outputId": "a1f444a3-f85e-4687-f655-4c8d69b7d368"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(18612, 18612, 2069, 2069)"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_sentences),len(train_labels),len(val_sentences), len(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZOaWdwyJDlq",
        "outputId": "ff702999-7cc7-48ef-b248-d1867667902c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(['Unfortunately, we do not routinely keep 20 liters of fentanyl in the pharmacy,',\n",
              "        '[NAME] instead of [NAME] for me, but glad to see [NAME] is doing well.',\n",
              "        'They look purple on my screen. But yes, tacky.',\n",
              "        'Holy fuck, report this now. The fuck you doing on reddit? ',\n",
              "        'I actually found mine today! I will give it to my 1 year old',\n",
              "        ' Their official logic is that it reduces turn-over, but yeah, the other reasons are kind of obvious.',\n",
              "        'Is there a source link? Id like to put it as my screen saver :)',\n",
              "        'FYI she’s probably cheating on someone, so didn’t want to post pics. ',\n",
              "        'How dare you interrupt the circle jerk. Out, sir.',\n",
              "        'The spouse sponsors them to guarantee that they are not a burden to the state. Nothing about this is related to committing a crime.'],\n",
              "       dtype=object),\n",
              " array([[False, False, False, False,  True, False],\n",
              "        [False,  True, False, False, False, False],\n",
              "        [False, False, False, False,  True, False],\n",
              "        [False, False,  True, False, False, False],\n",
              "        [False, False, False, False,  True, False],\n",
              "        [False, False, False, False,  True, False],\n",
              "        [False, False, False, False,  True, False],\n",
              "        [False, False, False, False,  True, False],\n",
              "        [False, False,  True, False, False, False],\n",
              "        [False, False, False, False,  True, False]]))"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checking the samples\n",
        "train_sentences[:10], train_labels[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MldYtu9JN5M"
      },
      "source": [
        "##converting text to numbers\n",
        "When dealing with text we needd to convert it into numbers\n",
        "\n",
        "there are a few ways to do this\n",
        "* Tokenisation- direct mapping of token(a token could be word or a character) to number\n",
        "* Embedding - create a matrix of feature vector for each token (size of the feature vector can be defined and this embedding can be learned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "DSZOoNyXJMp3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0YlgftPJT-X",
        "outputId": "10e44936-7148-4db4-cd09-65a398690f2a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'pipinstall' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!pipinstall tensorflow===2.10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "YgZR8gYAJY-d"
      },
      "outputs": [],
      "source": [
        "#using default textvectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                    split=\"whitespace\", # how to split tokens\n",
        "                                    ngrams=None, # create groups of n-words?\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n",
        "                                    # pad_to_max_tokens=True)9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V5Aif3TJcLa",
        "outputId": "84424501-291d-4c3d-9185-b0a3fd930d27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#find the average num of tokens in the training tweets\n",
        "round(sum([len(i.split())for i in train_sentences ])/len(train_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "sSYRWNHlJfPw"
      },
      "outputs": [],
      "source": [
        "#setup text vectorization variables\n",
        "max_vocab_length=10000 # max num of words to have in our vocabulary\n",
        "max_length= 100 #max length our sequences will be (eg how many words from a tweet does a model need to see)\\\n",
        "\n",
        "text_vectorizer=TextVectorization(max_tokens=max_vocab_length,\n",
        "                                  output_mode=\"int\",\n",
        "                                  output_sequence_length=max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "2dEluDqqJg0w"
      },
      "outputs": [],
      "source": [
        "#fit the text vecctorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L-Ap2SLJiZV",
        "outputId": "b714abc8-3d74-4aed-a62d-90faeda1d8b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 100), dtype=int64, numpy=\n",
              "array([[189,  43,  25, 620,   1, 380,  43, 392,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=int64)>"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_sentence=\"Wow we are finally implenting! aren't we great\"\n",
        "text_vectorizer([sample_sentence])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfhHhqPpJk_z",
        "outputId": "3b7104cf-dd87-429a-c575-5db54bf71414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original text; \n",
            " The dude even looks like [NAME]!        \n",
            "\n",
            " Vectorized version:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 100), dtype=int64, numpy=\n",
              "array([[  2, 211,  87, 138,  27,   6,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=int64)>"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "random_sentence=random.choice(train_sentences)\n",
        "print(f\"Original text; \\n {random_sentence}\\\n",
        "        \\n\\n Vectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyO6A9MrJn4r",
        "outputId": "f85c94a6-02ff-471b-f540-225a358860cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of words in vocab:10000\n",
            "5 most common words in vocab:['', '[UNK]', 'the', 'to', 'a']\n",
            "5 most least words in vocab:['tua', 'ttgl', 'ttc', 'tsunderes', 'tsm']\n"
          ]
        }
      ],
      "source": [
        "# Get the unique words in vocabulary\n",
        "words_in_vocab= text_vectorizer.get_vocabulary()\n",
        "top_5_words= words_in_vocab[:5]#get 5 most common\n",
        "bottom_5_words= words_in_vocab[-5:]#get 5 least common\n",
        "print(f\"Number of words in vocab:{len(words_in_vocab)}\")\n",
        "print(f\"5 most common words in vocab:{top_5_words}\")\n",
        "print(f\"5 most least words in vocab:{bottom_5_words}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y1U2w2EJxNt"
      },
      "source": [
        "##Creating embedding layer\n",
        "using tensors flows embeding layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2uHi5yvJsuY",
        "outputId": "bdc0fba7-566a-479d-a4c3-d2e282a3feae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.src.layers.core.embedding.Embedding at 0x24af51f5910>"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=max_length, # how long is each input\n",
        "                             name=\"embedding_1\")\n",
        "\n",
        "embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b--dNAKTJ7Di",
        "outputId": "82efba67-36e6-47a3-a3be-8855e18b816a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original text:\n",
            "And much like The Lions past, future and present it's not looking bright.      \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 100, 128), dtype=float32, numpy=\n",
              "array([[[ 0.04675734, -0.00284289,  0.03807788, ...,  0.00821386,\n",
              "          0.02006057, -0.00358471],\n",
              "        [-0.03699984, -0.01005615,  0.00360059, ..., -0.02572602,\n",
              "         -0.03605258, -0.01067047],\n",
              "        [ 0.03048461, -0.04675193, -0.02404611, ...,  0.00251601,\n",
              "          0.01514297,  0.00864362],\n",
              "        ...,\n",
              "        [-0.03659074, -0.01150005, -0.02675479, ...,  0.04134076,\n",
              "          0.04621175, -0.02526366],\n",
              "        [-0.03659074, -0.01150005, -0.02675479, ...,  0.04134076,\n",
              "          0.04621175, -0.02526366],\n",
              "        [-0.03659074, -0.01150005, -0.02675479, ...,  0.04134076,\n",
              "          0.04621175, -0.02526366]]], dtype=float32)>"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get a random sentence from training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIY0ka-PJ9YO",
        "outputId": "ff0b6eb0-ca38-4f6a-87d6-5e84182ad272"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([ 0.04675734, -0.00284289,  0.03807788,  0.02177956, -0.0123099 ,\n",
              "         0.01262507, -0.03022153,  0.03008265,  0.03821318,  0.04164277,\n",
              "         0.00959907,  0.00988804, -0.04491028,  0.0160881 , -0.04874025,\n",
              "        -0.02223467,  0.01323253,  0.01534236,  0.04867727,  0.00121498,\n",
              "         0.01974838, -0.03508626,  0.01540363,  0.03803864,  0.03683252,\n",
              "        -0.00659827,  0.00505308,  0.02317145,  0.04371906,  0.00955402,\n",
              "        -0.00958999, -0.04624399, -0.02399585,  0.01934614,  0.04316714,\n",
              "        -0.02506992,  0.03225431,  0.0435049 ,  0.01446399,  0.04216905,\n",
              "        -0.01963615, -0.04836488, -0.01920521, -0.02826532,  0.0057443 ,\n",
              "         0.01880224,  0.02687768, -0.0167627 ,  0.02657074, -0.00358479,\n",
              "        -0.0468533 ,  0.00950856, -0.00547479,  0.02608471, -0.03146863,\n",
              "         0.01271112, -0.01671817,  0.03850157, -0.00190351, -0.00771978,\n",
              "        -0.00656586,  0.01750262, -0.02722113,  0.0182342 , -0.00414765,\n",
              "         0.02952744, -0.03504444,  0.01160154, -0.03796135,  0.02320517,\n",
              "         0.02034212, -0.01778488,  0.04254048, -0.02705704,  0.02757693,\n",
              "        -0.02428027,  0.00623609, -0.03414726,  0.0173007 ,  0.0364644 ,\n",
              "        -0.00231326, -0.04936806,  0.02740288, -0.04591417,  0.00687397,\n",
              "         0.02832155, -0.03536745, -0.00248456, -0.00975268, -0.03135965,\n",
              "        -0.01921678, -0.01543807, -0.02463019,  0.01891484,  0.03739351,\n",
              "         0.02342136, -0.02616707,  0.03412059,  0.01211046,  0.02595856,\n",
              "        -0.00128572,  0.0407915 ,  0.04096463, -0.03436744,  0.02344123,\n",
              "         0.01442672,  0.0446607 ,  0.0288094 , -0.03402653,  0.03637887,\n",
              "         0.03116352, -0.02401814, -0.04204268, -0.04652789,  0.01981708,\n",
              "         0.03504575,  0.03420633,  0.00741332,  0.03131944, -0.04666736,\n",
              "        -0.01245213, -0.03762965, -0.02358167, -0.03646113, -0.02084724,\n",
              "         0.00821386,  0.02006057, -0.00358471], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 'A')"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfdl3k07KMx8"
      },
      "source": [
        "###Modelling a text dataset (running a series of experiements )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrNZ1xKeKkau"
      },
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "We can evaluate all of our model's predictions with different metrics every single time, but that will become very cumbersome.\n",
        "\n",
        "For this, we will create a function.\n",
        "\n",
        "Let's create one to compare our model's predictions with the truth labels using the following metrics: accuracy, precision, recall, f1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in c:\\users\\nishi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.2)Note: you may need to restart the kernel to use updated packages.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wget\n",
        "url=\"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\"\n",
        "filename=wget.download(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfeEmBAJTwir",
        "outputId": "45566aac-e0b9-4b04-8e63-92774f450ff2"
      },
      "outputs": [],
      "source": [
        "# Download helper functions script\n",
        "#wget \"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\"\n",
        "#import series of helper functions\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "kNpCENgg8EFG"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1 score\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Parameters:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results\n",
        "  # _ is used as an blank variable because we dont want 'support' which is a type of return in the function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsjcVqSIcsrP"
      },
      "source": [
        "##Model 1: A simple dense model\n",
        "The first \"deep\" model we're going to build is a single layer dense model. In fact, it's barely going to have a single layer.\n",
        "\n",
        "It'll take our text and labels as input, tokenize the text, create an embedding, find the average of the embedding (using Global Average Pooling) and then pass the average through a fully connected layer with one output unit and a sigmoid activation function.\n",
        "\n",
        "If the previous sentence sounds like a mouthful, it'll make sense when we code it out (remember, if in doubt, code it out).\n",
        "\n",
        "And since we're going to be building a number of TensorFlow deep learning models, we'll import our create_tensorboard_callback() function from helper_functions.py to keep track of the results of each.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlFf4Htsctvb",
        "outputId": "a173d3a1-0f7c-4583-8506-2ef3c930fb23"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nishi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1770: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "Jye50ehUc_uH"
      },
      "outputs": [],
      "source": [
        "# Create tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "LH-JSx0TdDCk"
      },
      "outputs": [],
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
        "outputs = layers.Dense(6, activation=\"softmax\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "HR11QRVmdEz2"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model_1.compile(loss=\"CategoricalCrossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdKcdlUsdGoW",
        "outputId": "512fab7b-9d88-4ec2-ec67-08e33a64e2aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_3 (Text  (None, 100)               0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 100, 128)          1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d_3  (None, 128)               0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1280774 (4.89 MB)\n",
            "Trainable params: 1280774 (4.89 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Get a summary of the model\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "sGTSKX3a05Ge"
      },
      "outputs": [],
      "source": [
        "train_sentences_list = train_sentences.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "GzeFdh0MF4Yx"
      },
      "outputs": [],
      "source": [
        "val_sentences_list = val_sentences.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4pKsqqx4Kt-",
        "outputId": "bbe8d709-4b6d-42c5-dce1-da505b1e5b50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(18612,)\n"
          ]
        }
      ],
      "source": [
        "print(train_sentences.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKIvZQr034MX",
        "outputId": "c57c3cd2-0792-4815-eb50-2ba3cf2d0404"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k4_Vv484ELF",
        "outputId": "850b4ebc-8e64-42e3-935c-15834a25fa68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(18612, 6)\n"
          ]
        }
      ],
      "source": [
        "print(train_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_jHfEXj2Wyu",
        "outputId": "392eaacf-ea5a-49b7-92e0-541ea5044482"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18612"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "cUMyZ4Fu2JBn"
      },
      "outputs": [],
      "source": [
        "train_labels[0]='1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6SAOAoxq5Mi",
        "outputId": "0eb9f04e-32cd-4950-a3c0-2e411ec10cce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ True,  True,  True,  True,  True,  True],\n",
              "       [False,  True, False, False, False, False],\n",
              "       [False, False, False, False,  True, False],\n",
              "       ...,\n",
              "       [False, False, False, False,  True, False],\n",
              "       [False, False,  True, False, False, False],\n",
              "       [False, False, False, False,  True, False]])"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voe8XF7ndMD-",
        "outputId": "e2cf828c-38c8-44b3-8c5e-e3622cda2ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20231002-133146\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "582/582 [==============================] - 33s 43ms/step - loss: 0.9491 - accuracy: 0.7666 - val_loss: 0.8762 - val_accuracy: 0.7753\n",
            "Epoch 2/5\n",
            "582/582 [==============================] - 26s 45ms/step - loss: 0.8590 - accuracy: 0.7746 - val_loss: 0.8495 - val_accuracy: 0.7753\n",
            "Epoch 3/5\n",
            "582/582 [==============================] - 30s 52ms/step - loss: 0.8194 - accuracy: 0.7746 - val_loss: 0.8121 - val_accuracy: 0.7753\n",
            "Epoch 4/5\n",
            "582/582 [==============================] - 23s 39ms/step - loss: 0.7621 - accuracy: 0.7759 - val_loss: 0.7697 - val_accuracy: 0.7796\n",
            "Epoch 5/5\n",
            "582/582 [==============================] - 24s 41ms/step - loss: 0.6965 - accuracy: 0.7852 - val_loss: 0.7255 - val_accuracy: 0.7864\n"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_sentences, #input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7QP3IIY4vQF",
        "outputId": "c1a731b7-ee72-4499-80f4-b9ab9ef97295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20231002-133409\n",
            "Epoch 1/10\n",
            "582/582 [==============================] - 27s 40ms/step - loss: 0.6308 - accuracy: 0.8018 - val_loss: 0.6932 - val_accuracy: 0.7927\n",
            "Epoch 2/10\n",
            "582/582 [==============================] - 24s 41ms/step - loss: 0.5719 - accuracy: 0.8193 - val_loss: 0.6566 - val_accuracy: 0.8062\n",
            "Epoch 3/10\n",
            "582/582 [==============================] - 23s 40ms/step - loss: 0.5195 - accuracy: 0.8362 - val_loss: 0.6425 - val_accuracy: 0.8125\n",
            "Epoch 4/10\n",
            "582/582 [==============================] - 24s 41ms/step - loss: 0.4750 - accuracy: 0.8498 - val_loss: 0.6230 - val_accuracy: 0.8188\n",
            "Epoch 5/10\n",
            "582/582 [==============================] - 24s 40ms/step - loss: 0.4368 - accuracy: 0.8612 - val_loss: 0.6181 - val_accuracy: 0.8299\n",
            "Epoch 6/10\n",
            "582/582 [==============================] - 24s 41ms/step - loss: 0.4032 - accuracy: 0.8714 - val_loss: 0.6187 - val_accuracy: 0.8304\n",
            "Epoch 7/10\n",
            "582/582 [==============================] - 24s 41ms/step - loss: 0.3733 - accuracy: 0.8819 - val_loss: 0.6035 - val_accuracy: 0.8352\n",
            "Epoch 8/10\n",
            "582/582 [==============================] - 23s 40ms/step - loss: 0.3463 - accuracy: 0.8893 - val_loss: 0.6040 - val_accuracy: 0.8357\n",
            "Epoch 9/10\n",
            "582/582 [==============================] - 23s 40ms/step - loss: 0.3226 - accuracy: 0.8983 - val_loss: 0.6396 - val_accuracy: 0.8352\n",
            "Epoch 10/10\n",
            "582/582 [==============================] - 24s 42ms/step - loss: 0.2999 - accuracy: 0.9037 - val_loss: 0.6163 - val_accuracy: 0.8342\n"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_sentences, #input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels,\n",
        "                              epochs=10,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3trU-Ov4LJsb",
        "outputId": "9648e855-646b-472c-ce57-11cec746b68e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65/65 [==============================] - 4s 4ms/step - loss: 0.6163 - accuracy: 0.8342\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.6162972450256348, 0.8342194557189941]"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the results on the validation set\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7hLDBtXLQT7",
        "outputId": "db507311-c5a5-4643-fa48-8a639328bc7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Variable 'embedding_1/embeddings:0' shape=(10000, 128) dtype=float32, numpy=\n",
              " array([[ 0.01749581,  0.01260641, -0.01870494, ...,  0.02141483,\n",
              "          0.07239529, -0.00778649],\n",
              "        [ 0.02234323,  0.08045591,  0.00493355, ...,  0.04392124,\n",
              "          0.01940883,  0.11110722],\n",
              "        [ 0.00588627,  0.07957175, -0.16530548, ...,  0.17074867,\n",
              "         -0.02886324,  0.02415207],\n",
              "        ...,\n",
              "        [-0.15925863,  0.26103306,  0.27438253, ..., -0.30591372,\n",
              "          0.23096189,  0.29640594],\n",
              "        [-0.22708572,  0.34481058,  0.34810793, ..., -0.2953097 ,\n",
              "          0.30620143,  0.33223784],\n",
              "        [-0.25870195,  0.2530055 ,  0.33695683, ..., -0.2524075 ,\n",
              "          0.30056027,  0.25313804]], dtype=float32)>]"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding.weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKYZRoJ5LSyw",
        "outputId": "3e98af23-c8be-40b0-b356-32004060a835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ],
      "source": [
        "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
        "print(embed_weights.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGLjGcKV5NRE",
        "outputId": "ee2ee59b-c3ad-4bcd-b71f-3b87f084e253"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65/65 [==============================] - 4s 2ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[6.72646146e-03, 6.73266128e-03, 1.72097869e-02, 1.96661986e-02,\n",
              "        9.34183180e-01, 1.54817607e-02],\n",
              "       [2.09653028e-03, 3.91698349e-03, 1.32487919e-02, 6.83992961e-03,\n",
              "        9.68367815e-01, 5.52997040e-03],\n",
              "       [1.02324180e-01, 1.31858774e-02, 6.08205236e-02, 2.42052693e-02,\n",
              "        1.49467304e-01, 6.49996877e-01],\n",
              "       [1.21550541e-02, 5.77107705e-02, 1.87415276e-02, 1.62808634e-02,\n",
              "        8.69417727e-01, 2.56940685e-02],\n",
              "       [7.61854416e-03, 8.10942985e-03, 5.10239713e-02, 1.59185063e-02,\n",
              "        8.75872374e-01, 4.14571203e-02],\n",
              "       [8.26168247e-03, 6.63280347e-03, 8.92902732e-01, 1.25561273e-02,\n",
              "        6.98544458e-02, 9.79215093e-03],\n",
              "       [8.98904353e-02, 7.34748304e-01, 8.48543830e-04, 3.13260891e-02,\n",
              "        4.19635549e-02, 1.01223163e-01],\n",
              "       [6.63992530e-03, 3.93430889e-03, 3.18254501e-01, 1.49365831e-02,\n",
              "        6.33677661e-01, 2.25569997e-02],\n",
              "       [3.34010310e-02, 2.16732807e-02, 1.53592583e-02, 5.21099903e-02,\n",
              "        7.74931908e-01, 1.02524571e-01],\n",
              "       [1.00609366e-04, 2.55806517e-04, 3.93958500e-04, 2.53014179e-04,\n",
              "        9.98350859e-01, 6.45792461e-04],\n",
              "       [1.51385069e-01, 5.05983271e-02, 6.42978773e-02, 1.67492256e-02,\n",
              "        6.20251656e-01, 9.67179462e-02],\n",
              "       [2.16695917e-04, 1.26917861e-04, 2.30350555e-03, 1.69078368e-04,\n",
              "        9.94931757e-01, 2.25202437e-03],\n",
              "       [3.44771426e-03, 2.58936873e-03, 3.57216001e-02, 5.33842202e-03,\n",
              "        9.43515420e-01, 9.38743167e-03],\n",
              "       [2.95515754e-04, 3.62922699e-04, 2.33211857e-03, 4.51184576e-04,\n",
              "        9.87695456e-01, 8.86279810e-03],\n",
              "       [6.88786153e-03, 3.93602485e-03, 1.11204367e-02, 1.21668112e-02,\n",
              "        9.39678550e-01, 2.62102410e-02],\n",
              "       [7.26711805e-05, 1.84050281e-04, 1.08598417e-03, 1.23031321e-04,\n",
              "        9.97854769e-01, 6.79462275e-04],\n",
              "       [1.76708540e-03, 6.33488118e-04, 4.99606021e-02, 1.38931000e-03,\n",
              "        9.41223562e-01, 5.02589438e-03],\n",
              "       [5.06038889e-02, 6.69020191e-02, 1.10417962e-01, 3.58816311e-02,\n",
              "        6.16094828e-01, 1.20099694e-01],\n",
              "       [1.98453339e-03, 2.29423959e-03, 6.59220144e-02, 2.06942819e-02,\n",
              "        8.97127628e-01, 1.19772935e-02],\n",
              "       [2.32635229e-03, 4.94087813e-03, 3.57687771e-02, 4.08159103e-03,\n",
              "        9.42801058e-01, 1.00813471e-02]], dtype=float32)"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make predictions (these come back in the form of probabilities)\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs[:20] # only print out the first 10 prediction probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzA_ReqZ8u3w",
        "outputId": "af98d941-5c96-494d-bb25-52ac1a39e364"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20, 6), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.]], dtype=float32)>"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Turn prediction probabilities into single-dimension tensor of floats\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze removes single dimensions\n",
        "model_1_preds[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8ODp9YC8zDa",
        "outputId": "0a9dbaef-f088-42bc-83fe-8a68f1f60c25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 81.15031416143064,\n",
              " 'precision': 0.8370417508397358,\n",
              " 'recall': 0.8115031416143065,\n",
              " 'f1': 0.8054798017975526}"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate model_1 metrics\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8iABj7J-Stb"
      },
      "source": [
        "###Model 2: LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFnC49qi-EBq",
        "outputId": "9afa8d1b-e55a-4631-c091-797b55b4c6a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(None, 100, 128)\n",
            "(None, 64)\n"
          ]
        }
      ],
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_2\")\n",
        "\n",
        "\n",
        "# Create LSTM model\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_2_embedding(x)\n",
        "print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
        "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
        "print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
        "outputs = layers.Dense(6, activation=\"softmax\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "HBFEC9TS-c5G"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model_2.compile(loss=\"CategoricalCrossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8fc5Koi-fBq",
        "outputId": "681cea13-0905-4b2b-e084-e75651d8dd5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_3 (Text  (None, 100)               0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 100, 128)          1280000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1329798 (5.07 MB)\n",
            "Trainable params: 1329798 (5.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIX60NFi-iUv",
        "outputId": "fd0dc403-8986-4dad-ff1e-2556ac64941b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/LSTM/20231002-134152\n",
            "Epoch 1/5\n",
            "582/582 [==============================] - 60s 89ms/step - loss: 0.9074 - accuracy: 0.7732 - val_loss: 0.8960 - val_accuracy: 0.7753\n",
            "Epoch 2/5\n",
            "582/582 [==============================] - 52s 89ms/step - loss: 0.8916 - accuracy: 0.7746 - val_loss: 0.8931 - val_accuracy: 0.7753\n",
            "Epoch 3/5\n",
            "582/582 [==============================] - 51s 88ms/step - loss: 0.8909 - accuracy: 0.7746 - val_loss: 0.8958 - val_accuracy: 0.7753\n",
            "Epoch 4/5\n",
            "582/582 [==============================] - 52s 90ms/step - loss: 0.8906 - accuracy: 0.7746 - val_loss: 0.8962 - val_accuracy: 0.7753\n",
            "Epoch 5/5\n",
            "582/582 [==============================] - 58s 100ms/step - loss: 0.8905 - accuracy: 0.7746 - val_loss: 0.8969 - val_accuracy: 0.7753\n"
          ]
        }
      ],
      "source": [
        "# Fit model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"LSTM\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/LSTM/20231002-134629\n",
            "Epoch 1/10\n",
            "582/582 [==============================] - 98s 156ms/step - loss: 0.8906 - accuracy: 0.7746 - val_loss: 0.8942 - val_accuracy: 0.7753\n",
            "Epoch 2/10\n",
            "582/582 [==============================] - 86s 148ms/step - loss: 0.8906 - accuracy: 0.7746 - val_loss: 0.8935 - val_accuracy: 0.7753\n",
            "Epoch 3/10\n",
            "582/582 [==============================] - 126s 217ms/step - loss: 0.8902 - accuracy: 0.7746 - val_loss: 0.8955 - val_accuracy: 0.7753\n",
            "Epoch 4/10\n",
            "582/582 [==============================] - 76s 130ms/step - loss: 0.8903 - accuracy: 0.7746 - val_loss: 0.8955 - val_accuracy: 0.7753\n",
            "Epoch 5/10\n",
            "582/582 [==============================] - 67s 115ms/step - loss: 0.8902 - accuracy: 0.7746 - val_loss: 0.8960 - val_accuracy: 0.7753\n",
            "Epoch 6/10\n",
            "582/582 [==============================] - 67s 115ms/step - loss: 0.8905 - accuracy: 0.7746 - val_loss: 0.8961 - val_accuracy: 0.7753\n",
            "Epoch 7/10\n",
            "582/582 [==============================] - 62s 107ms/step - loss: 0.8906 - accuracy: 0.7745 - val_loss: 0.8953 - val_accuracy: 0.7753\n",
            "Epoch 8/10\n",
            "582/582 [==============================] - 62s 107ms/step - loss: 0.8904 - accuracy: 0.7746 - val_loss: 0.8957 - val_accuracy: 0.7753\n",
            "Epoch 9/10\n",
            "582/582 [==============================] - 66s 113ms/step - loss: 0.8904 - accuracy: 0.7746 - val_loss: 0.8968 - val_accuracy: 0.7753\n",
            "Epoch 10/10\n",
            "582/582 [==============================] - 57s 98ms/step - loss: 0.8904 - accuracy: 0.7746 - val_loss: 0.8965 - val_accuracy: 0.7753\n"
          ]
        }
      ],
      "source": [
        "# Fit model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=10,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"LSTM\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG_qJ4pY-nj-",
        "outputId": "76c5abe8-a039-4778-da17-b0cdf1b04b07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65/65 [==============================] - 7s 19ms/step\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the validation dataset\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "#model_2_pred_probs.shape, model_2_pred_probs[:10] # view the first 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wqsKkE8-tMQ",
        "outputId": "77d2d150-d80d-4ebb-9532-93ce1babd6a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20, 6), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.]], dtype=float32)>"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Round out predictions and reduce to 1-dimensional array\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nishi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'accuracy': 77.52537457709037,\n",
              " 'precision': 0.6010183703318172,\n",
              " 'recall': 0.7752537457709038,\n",
              " 'f1': 0.6771070014791885}"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate LSTM model results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkJMZCD2_fDu"
      },
      "source": [
        "###Model 3: GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "CMF7_xBd_hfn"
      },
      "outputs": [],
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_3\")\n",
        "\n",
        "# Build an RNN using the GRU cell\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells requires return_sequences=True\n",
        "x = layers.GRU(128)(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
        "outputs = layers.Dense(6, activation=\"softmax\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "uSjWGu5Q_oxY"
      },
      "outputs": [],
      "source": [
        "# Compile GRU model\n",
        "model_3.compile(loss=\"CategoricalCrossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGHHvFdV_p87",
        "outputId": "52a6d5e2-7f32-4097-e953-b3b73b8caaa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_3 (Text  (None, 100)               0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 100, 128)          1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 128)               99072     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1379846 (5.26 MB)\n",
            "Trainable params: 1379846 (5.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Get a summary of the GRU model\n",
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Iwhk-6c_sjc",
        "outputId": "ea339458-afbf-465a-a6d9-47ae385f5246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20231002-140001\n",
            "Epoch 1/4\n",
            "582/582 [==============================] - 77s 121ms/step - loss: 0.9078 - accuracy: 0.7732 - val_loss: 0.9031 - val_accuracy: 0.7753\n",
            "Epoch 2/4\n",
            "582/582 [==============================] - 95s 164ms/step - loss: 0.8945 - accuracy: 0.7746 - val_loss: 0.8936 - val_accuracy: 0.7753\n",
            "Epoch 3/4\n",
            "582/582 [==============================] - 84s 143ms/step - loss: 0.8927 - accuracy: 0.7746 - val_loss: 0.8965 - val_accuracy: 0.7753\n",
            "Epoch 4/4\n",
            "582/582 [==============================] - 89s 154ms/step - loss: 0.8920 - accuracy: 0.7746 - val_loss: 0.9016 - val_accuracy: 0.7753\n"
          ]
        }
      ],
      "source": [
        "# Fit model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=4,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20231002-140757\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32md:\\Personal\\Nishika Singhvi\\Project\\Multiple_emotions_NLP_Implementation_Reddit.ipynb Cell 105\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal/Nishika%20Singhvi/Project/Multiple_emotions_NLP_Implementation_Reddit.ipynb#Y205sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Fit model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Personal/Nishika%20Singhvi/Project/Multiple_emotions_NLP_Implementation_Reddit.ipynb#Y205sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_3_history \u001b[39m=\u001b[39m model_3\u001b[39m.\u001b[39;49mfit(train_sentences,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal/Nishika%20Singhvi/Project/Multiple_emotions_NLP_Implementation_Reddit.ipynb#Y205sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                               train_labels,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal/Nishika%20Singhvi/Project/Multiple_emotions_NLP_Implementation_Reddit.ipynb#Y205sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                               epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal/Nishika%20Singhvi/Project/Multiple_emotions_NLP_Implementation_Reddit.ipynb#Y205sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                               validation_data\u001b[39m=\u001b[39;49m(val_sentences, val_labels),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal/Nishika%20Singhvi/Project/Multiple_emotions_NLP_Implementation_Reddit.ipynb#Y205sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                               callbacks\u001b[39m=\u001b[39;49m[create_tensorboard_callback(SAVE_DIR, \u001b[39m\"\u001b[39;49m\u001b[39mGRU\u001b[39;49m\u001b[39m\"\u001b[39;49m)])\n",
            "File \u001b[1;32mc:\\Users\\nishi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\nishi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[1;32mc:\\Users\\nishi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\nishi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\nishi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[1;32mc:\\Users\\nishi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[1;32mc:\\Users\\nishi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\nishi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
            "File \u001b[1;32mc:\\Users\\nishi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
            "File \u001b[1;32mc:\\Users\\nishi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Fit model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=10,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnk3kTD2_w1c",
        "outputId": "d43998dc-f9b7-42f9-84e5-f5581429d3b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65/65 [==============================] - 6s 25ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "((2069, 6),\n",
              " array([[0.01751247, 0.04189602, 0.03979018, 0.03681311, 0.8250881 ,\n",
              "         0.03890003],\n",
              "        [0.01751247, 0.04189602, 0.03979018, 0.03681311, 0.8250881 ,\n",
              "         0.03890003],\n",
              "        [0.01751247, 0.04189602, 0.03979018, 0.03681311, 0.8250881 ,\n",
              "         0.03890003],\n",
              "        [0.01751247, 0.04189602, 0.03979018, 0.03681311, 0.8250881 ,\n",
              "         0.03890003],\n",
              "        [0.01751247, 0.04189602, 0.03979018, 0.03681311, 0.8250881 ,\n",
              "         0.03890004],\n",
              "        [0.01751247, 0.04189602, 0.03979018, 0.03681311, 0.8250881 ,\n",
              "         0.03890004],\n",
              "        [0.01751247, 0.04189602, 0.03979018, 0.03681311, 0.8250881 ,\n",
              "         0.03890003],\n",
              "        [0.01751247, 0.04189602, 0.03979018, 0.03681311, 0.8250881 ,\n",
              "         0.03890003],\n",
              "        [0.01751247, 0.04189602, 0.03979018, 0.03681311, 0.8250881 ,\n",
              "         0.03890003],\n",
              "        [0.01751247, 0.04189602, 0.03979018, 0.03681311, 0.8250881 ,\n",
              "         0.03890003]], dtype=float32))"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make predictions on the validation data\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs.shape, model_3_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7o7oSB6Y_2O3",
        "outputId": "431f107f-0bfa-4bb1-c48e-d4daf236e57c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 6), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.]], dtype=float32)>"
            ]
          },
          "execution_count": 171,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert prediction probabilities to prediction classes\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPvvtHqS_9Ks",
        "outputId": "509728ca-3474-4b38-fda4-01c0b2c10a0d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nishi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'accuracy': 77.52537457709037,\n",
              " 'precision': 0.6010183703318172,\n",
              " 'recall': 0.7752537457709038,\n",
              " 'f1': 0.6771070014791885}"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calcuate model_3 results\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wj9OXUyL__dV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q29sdKBYAR6U"
      },
      "source": [
        "###Model 4: Bidirectonal RNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "gVX7j5VPATnh"
      },
      "outputs": [],
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_4\")\n",
        "\n",
        "# Build a Bidirectional RNN in TensorFlow\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_4_embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
        "outputs = layers.Dense(6, activation=\"softmax\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "lGSytT37AWQB"
      },
      "outputs": [],
      "source": [
        "# Compile\n",
        "model_4.compile(loss=\"CategoricalCrossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYw-FgnaAYg-",
        "outputId": "edc9a4c8-11b2-4783-c123-6bbbfc1a7dcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4_Bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_3 (Text  (None, 100)               0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 100, 128)          1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 128)               98816     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1379590 (5.26 MB)\n",
            "Trainable params: 1379590 (5.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Get a summary of our bidirectional model\n",
        "model_4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXc3mj9JAapx",
        "outputId": "0390d04b-300d-4100-b556-2d13011b1bd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20231002-142807\n",
            "Epoch 1/4\n",
            "582/582 [==============================] - 77s 128ms/step - loss: 0.0494 - accuracy: 0.9848 - val_loss: 1.1926 - val_accuracy: 0.8096\n",
            "Epoch 2/4\n",
            "582/582 [==============================] - 71s 122ms/step - loss: 0.0434 - accuracy: 0.9872 - val_loss: 1.1430 - val_accuracy: 0.7960\n",
            "Epoch 3/4\n",
            "582/582 [==============================] - 76s 131ms/step - loss: 0.0374 - accuracy: 0.9888 - val_loss: 1.2891 - val_accuracy: 0.8043\n",
            "Epoch 4/4\n",
            "582/582 [==============================] - 76s 131ms/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 1.2877 - val_accuracy: 0.7864\n"
          ]
        }
      ],
      "source": [
        "# Fit the model (takes longer because of the bidirectional layers)\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=4,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20231002-141541\n",
            "Epoch 1/7\n",
            "582/582 [==============================] - 107s 178ms/step - loss: 0.1710 - accuracy: 0.9450 - val_loss: 0.7161 - val_accuracy: 0.8342\n",
            "Epoch 2/7\n",
            "582/582 [==============================] - 92s 158ms/step - loss: 0.1331 - accuracy: 0.9591 - val_loss: 0.7379 - val_accuracy: 0.8255\n",
            "Epoch 3/7\n",
            "582/582 [==============================] - 81s 139ms/step - loss: 0.1039 - accuracy: 0.9681 - val_loss: 0.7778 - val_accuracy: 0.8173\n",
            "Epoch 4/7\n",
            "582/582 [==============================] - 83s 142ms/step - loss: 0.0872 - accuracy: 0.9734 - val_loss: 0.9164 - val_accuracy: 0.8197\n",
            "Epoch 5/7\n",
            "582/582 [==============================] - 85s 146ms/step - loss: 0.0751 - accuracy: 0.9765 - val_loss: 0.9976 - val_accuracy: 0.8057\n",
            "Epoch 6/7\n",
            "582/582 [==============================] - 81s 139ms/step - loss: 0.0599 - accuracy: 0.9816 - val_loss: 1.0834 - val_accuracy: 0.7999\n",
            "Epoch 7/7\n",
            "582/582 [==============================] - 98s 168ms/step - loss: 0.0553 - accuracy: 0.9836 - val_loss: 1.0377 - val_accuracy: 0.8134\n"
          ]
        }
      ],
      "source": [
        "# Fit the model (takes longer because of the bidirectional layers)\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=7,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd3armMEAivG",
        "outputId": "dcb9d300-ac41-494a-cb03-a37283e9ac84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65/65 [==============================] - 5s 24ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1.27472163e-06, 2.02283372e-05, 3.62192941e-06, 2.04213466e-02,\n",
              "        9.79477525e-01, 7.59564136e-05],\n",
              "       [1.08200754e-06, 3.98605662e-05, 5.24685020e-04, 7.86912005e-06,\n",
              "        9.99256432e-01, 1.70107814e-04],\n",
              "       [3.58212528e-05, 5.41646659e-05, 4.30445973e-04, 2.48341530e-05,\n",
              "        2.87045818e-02, 9.70750093e-01],\n",
              "       [1.12806032e-04, 1.36321655e-03, 1.51202854e-04, 5.09037403e-03,\n",
              "        9.93263304e-01, 1.90698702e-05],\n",
              "       [4.60788556e-07, 3.00238753e-06, 1.66061964e-05, 6.80627409e-07,\n",
              "        9.99976873e-01, 2.36966298e-06],\n",
              "       [8.65849688e-06, 3.34758420e-06, 9.91882622e-01, 4.70884734e-05,\n",
              "        8.00908823e-03, 4.92014478e-05],\n",
              "       [2.40945183e-02, 9.65341508e-01, 1.99965107e-05, 3.80170392e-03,\n",
              "        4.80216835e-03, 1.94012851e-03],\n",
              "       [6.96788948e-06, 8.49356275e-06, 6.81178153e-01, 4.11829315e-05,\n",
              "        3.17246169e-01, 1.51902193e-03],\n",
              "       [3.10799049e-04, 1.15766056e-01, 1.20359015e-04, 1.21650904e-04,\n",
              "        8.81471217e-01, 2.20991485e-03],\n",
              "       [5.33156126e-05, 1.22753624e-03, 2.75697885e-03, 9.88772081e-06,\n",
              "        9.95909214e-01, 4.31009721e-05]], dtype=float32)"
            ]
          },
          "execution_count": 191,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make predictions with bidirectional RNN on the validation data\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxtyL1D_AjfS",
        "outputId": "04408b4a-2e97-4603-be40-951f7515f27f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 6), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.]], dtype=float32)>"
            ]
          },
          "execution_count": 192,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS2K1zaHAmDc",
        "outputId": "d6bff37d-1b03-47ce-f3bb-639f836c6eca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 78.10536491058483,\n",
              " 'precision': 0.7920895908849387,\n",
              " 'recall': 0.7810536491058483,\n",
              " 'f1': 0.7848738146068309}"
            ]
          },
          "execution_count": 193,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate bidirectional RNN model results\n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuRNhdwkBCPZ",
        "outputId": "41af801c-964c-4e71-c7ad-4d262cb585b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 81.15031416143064,\n",
              " 'precision': 0.8370417508397358,\n",
              " 'recall': 0.8115031416143065,\n",
              " 'f1': 0.8054798017975526}"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_1_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1w4zUhPBDrv",
        "outputId": "5a65636b-3086-4be8-afdf-d27ef55f661d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 77.52537457709037,\n",
              " 'precision': 0.6010183703318172,\n",
              " 'recall': 0.7752537457709038,\n",
              " 'f1': 0.6771070014791885}"
            ]
          },
          "execution_count": 184,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_2_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEarDtx3BFFU",
        "outputId": "c0716d9c-5f75-492a-84b3-604717aee9fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 77.52537457709037,\n",
              " 'precision': 0.6010183703318172,\n",
              " 'recall': 0.7752537457709038,\n",
              " 'f1': 0.6771070014791885}"
            ]
          },
          "execution_count": 185,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_3_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmEhuexfBGtQ",
        "outputId": "148a316d-5d84-4ea1-d81a-3fce40e62c41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 80.95698405026583,\n",
              " 'precision': 0.8020115068954726,\n",
              " 'recall': 0.8095698405026583,\n",
              " 'f1': 0.8023252964813339}"
            ]
          },
          "execution_count": 186,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_4_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvNgh-9JBIdB",
        "outputId": "59f04a77-fe67-4020-bfc7-3ae7fa11c590"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[9.9717760e-01, 1.2619295e-03, 1.5097355e-05, 2.9596410e-04,\n",
              "        1.9788225e-04, 1.0514916e-03],\n",
              "       [8.5296415e-06, 9.9933404e-01, 5.6285517e-06, 1.8441358e-05,\n",
              "        4.5107582e-04, 1.8216284e-04],\n",
              "       [4.5085912e-05, 2.1684601e-04, 9.5594460e-01, 2.5521434e-04,\n",
              "        3.9642613e-02, 3.8956439e-03],\n",
              "       [5.3788413e-06, 1.4964856e-05, 1.8565357e-06, 9.9891913e-01,\n",
              "        8.6639315e-04, 1.9222761e-04],\n",
              "       [2.0064172e-05, 9.6673250e-07, 3.2276764e-06, 5.8622646e-07,\n",
              "        1.6004953e-04, 9.9981517e-01]], dtype=float32)"
            ]
          },
          "execution_count": 196,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 2:anger, 9:disappointment, 14:fear, 17:joy, 26:surprise, 27:neutral\n",
        "sen=['i am scared','i am happy','i am angry', 'i am surprised','i am disappointed']\n",
        "guess=model_4.predict(sen)\n",
        "guess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DNpHCWy8n9h",
        "outputId": "b9fe7b6f-6592-49d1-9575-07f27b57be18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 6), dtype=float32, numpy=\n",
              "array([[1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1.]], dtype=float32)>"
            ]
          },
          "execution_count": 197,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.squeeze(tf.round(guess))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wg1JpK6a9FWA"
      },
      "outputs": [],
      "source": [
        "#14-fear, 17-joy, 2-angry, 25- sadnessS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def translate_text(text, target_language='en'):\n",
        "    # Initialize the translator\n",
        "    translator = Translator()\n",
        "\n",
        "    # Translate the text to the target language\n",
        "    translation = translator.translate(text, dest=target_language)\n",
        "\n",
        "    return translation.text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence has been passed\n",
            "['i am so happy']\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "tf.Tensor([0. 1. 0. 0. 0. 0.], shape=(6,), dtype=float32)\n",
            "answer:  Joy\n"
          ]
        }
      ],
      "source": [
        "sen=input(\"Please enter a sentence: \")\n",
        "def analysis(sentence):\n",
        "   print(\"Sentence has been passed\")\n",
        "   print(sentence)\n",
        "   # translated_input= translate_text(sentence, target_language='en')\n",
        "   answer= model_4.predict(sentence)\n",
        "   result=tf.squeeze(tf.round(answer))\n",
        "   print(result)\n",
        "   \n",
        "   first_element = result[0]\n",
        "   second_element = result[1]\n",
        "   third_element = result[2]\n",
        "   fourth_element = result[3]\n",
        "   fifth_element = result[4]\n",
        "   sixth_element = result[5]\n",
        "   \n",
        "\n",
        "   if(first_element==1 and second_element==0 and third_element==0 and fourth_element==0 and fifth_element==0 and sixth_element==0):\n",
        "      return(\"Fear\")\n",
        "   elif(first_element==0 and second_element==1 and third_element==0 and fourth_element==0 and fifth_element==0 and sixth_element==0):\n",
        "      return(\"Joy\")\n",
        "   elif(first_element==0 and second_element==0 and third_element==1 and fourth_element==0 and fifth_element==0 and sixth_element==0):\n",
        "      return(\"Angry\")\n",
        "   elif(first_element==0 and second_element==0 and third_element==0 and fourth_element==1 and fifth_element==0 and sixth_element==0):\n",
        "      return(\"Surprise\")\n",
        "   elif(first_element==0 and second_element==0 and third_element==0 and fourth_element==0 and fifth_element==1 and sixth_element==0):\n",
        "      return(\"Neutral\")\n",
        "   else:return(\"Disappointed\")\n",
        "   \n",
        "answer1 = analysis([sen])\n",
        "print(\"answer: \", answer1)\n",
        "   "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
